{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40eb0049-48d4-4567-b809-c7cb448d1544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly identified (True Positives): 863\n",
      "Correctly rejected (True Negatives): 911\n",
      "Incorrectly identified (False Positives): 167\n",
      "Failed to identify (False Negatives): 137\n",
      "Precision: 0.84\n",
      "Recall: 0.86\n",
      "F1 Score: 0.85\n",
      "Model Accuracy: 85.37%\n",
      "Balanced Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "    \n",
    "# Bulk testing to find the metrics for the different values of match-threshold and distance-threshold\n",
    "\n",
    "# Enhance image quality using CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "def enhance_image(image):\n",
    "    \"\"\"Enhance image quality.\"\"\"\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_image = clahe.apply(image)\n",
    "    return enhanced_image\n",
    "\n",
    "# Load images from a folder and apply enhancement\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename), 0)  # Load as grayscale\n",
    "        if img is not None:\n",
    "            img = enhance_image(img)  # Enhance the image\n",
    "            images.append((filename, img))\n",
    "    return images\n",
    "\n",
    "# Check similarity between template and image using ORB feature detection and matching\n",
    "def is_similar(template, image, match_threshold=15, distance_threshold=30):\n",
    "    orb = cv2.ORB_create()\n",
    "    kp1, des1 = orb.detectAndCompute(template, None)\n",
    "    kp2, des2 = orb.detectAndCompute(image, None)\n",
    "\n",
    "    if des1 is None or des2 is None:  # If no descriptors are found\n",
    "        return False\n",
    "\n",
    "    # Match descriptors using BFMatcher with Hamming distance and crossCheck\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)  # Sort by distance\n",
    "\n",
    "    # Filter \"good matches\" based on the distance threshold\n",
    "    good_matches = [m for m in matches if m.distance < distance_threshold]\n",
    "    return len(good_matches) > match_threshold  # Return True if enough good matches\n",
    "\n",
    "# Test the model by evaluating performance on both correct and incorrect image sets\n",
    "def test_model(template_path, correct_folder, incorrect_folder, match_threshold=11, distance_threshold=47):\n",
    "   \n",
    "    # Print the current match and distance thresholds\n",
    "    print(f\"Testing with match_threshold = {match_threshold} and distance_threshold = {distance_threshold}\")\n",
    "\n",
    "    template = cv2.imread(template_path, 0)  # Load template as grayscale\n",
    "    if template is None:\n",
    "        raise FileNotFoundError(f\"Template image '{template_path}' not found.\")\n",
    "\n",
    "    template = enhance_image(template)  # Enhance the template image\n",
    "\n",
    "    # Load correct and incorrect images\n",
    "    correct_images = load_images_from_folder(correct_folder)\n",
    "    incorrect_images = load_images_from_folder(incorrect_folder)\n",
    "\n",
    "    # Initialize performance metrics\n",
    "    TP, TN, FP, FN = 0, 0, 0, 0\n",
    "\n",
    "    # Evaluate correct images\n",
    "    for filename, img in correct_images:\n",
    "        if is_similar(template, img, match_threshold, distance_threshold):\n",
    "            TP += 1  # True Positive\n",
    "        else:\n",
    "            FN += 1  # False Negative\n",
    "\n",
    "    # Evaluate incorrect images\n",
    "    for filename, img in incorrect_images:\n",
    "        if not is_similar(template, img, match_threshold, distance_threshold):\n",
    "            TN += 1  # True Negative\n",
    "        else:\n",
    "            FP += 1  # False Positive\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN) * 100\n",
    "    TPR = TP / (TP + FN) if (TP + FN) > 0 else 0  # True Positive Rate (Recall)\n",
    "    TNR = TN / (TN + FP) if (TN + FP) > 0 else 0  # True Negative Rate (Specificity)\n",
    "    balanced_accuracy = (TPR + TNR) / 2  # Balanced Accuracy\n",
    "    \n",
    "    # Print performance results\n",
    "    print(f\"Correctly identified (True Positives): {TP}\")\n",
    "    print(f\"Correctly rejected (True Negatives): {TN}\")\n",
    "    print(f\"Incorrectly identified (False Positives): {FP}\")\n",
    "    print(f\"Failed to identify (False Negatives): {FN}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1_score:.2f}\")\n",
    "    print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Balanced Accuracy: {balanced_accuracy:.2f}\")\n",
    "\n",
    "# Define file paths and folders\n",
    "template_path = r\"C:\\Users\\Khang Trung Nguyen\\Amanda4\\esp_captured\\template_3.jpg\"\n",
    "correct_folder = r\"C:\\Users\\Khang Trung Nguyen\\Amanda4\\augmented_esp_images\"\n",
    "incorrect_folder = r\"data\\incorrect_objects\"\n",
    "\n",
    "# Run the test\n",
    "test_model(template_path, correct_folder, incorrect_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89df7c8a-e924-43ab-9baa-f24b1dd17cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing one image with the best distance- and match-threshold\n",
    "\n",
    "# Define a function to enhance the image quality using CLAHE\n",
    "def enhance_image(image):\n",
    "    \"\"\"Enhance image quality by applying Contrast Limited Adaptive Histogram Equalization (CLAHE).\"\"\"\n",
    "    # Apply CLAHE with clipLimit of 2.0 and tileGridSize of 8x8\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_image = clahe.apply(image)  # Apply CLAHE to the image\n",
    "    return enhanced_image\n",
    "\n",
    "# Load the template (reference image) and the test image where you want to find the sticker\n",
    "template = cv2.imread(r\"C:\\Users\\Khang Trung Nguyen\\Amanda4\\esp_captured\\template_3.jpg\", 0)  # Load template in grayscale\n",
    "image = cv2.imread(r\"C:\\Users\\Khang Trung Nguyen\\Amanda4\\esp_captured\\test_a1.jpg\", 0)  # Load test image in grayscale\n",
    "\n",
    "# Enhance both images using the enhance_image function\n",
    "template = enhance_image(template)  # Enhance the template image\n",
    "image = enhance_image(image)  # Enhance the test image\n",
    "\n",
    "# Initialize ORB detector to find keypoints and descriptors\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# Detect keypoints and compute descriptors for both the template and the test image\n",
    "kp1, des1 = orb.detectAndCompute(template, None)  # Detect keypoints and descriptors in template\n",
    "kp2, des2 = orb.detectAndCompute(image, None)  # Detect keypoints and descriptors in test image\n",
    "\n",
    "# Use BFMatcher with Hamming distance and cross-checking to match descriptors between template and image\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = bf.match(des1, des2)  # Match the descriptors between the two images\n",
    "\n",
    "# Sort matches based on distance, so the best matches come first\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "# Log the total number of matches found between the two images\n",
    "total_matches = len(matches)\n",
    "print(f\"Total Matches: {total_matches}\")\n",
    "\n",
    "# Filter \"good matches\" by setting a distance threshold for the match quality\n",
    "distance_threshold = 47  # Threshold for considering matches as \"good\"\n",
    "good_matches = [m for m in matches if m.distance < distance_threshold]  # Keep only the matches below the threshold\n",
    "\n",
    "# Log the number of good matches\n",
    "good_matches_count = len(good_matches)\n",
    "print(f\"Good Matches: {good_matches_count}\")\n",
    "\n",
    "# Draw the top 10 matches between the template and the test image\n",
    "matched_image = cv2.drawMatches(template, kp1, image, kp2, matches[:10], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "# Display the matched image using Matplotlib\n",
    "plt.imshow(matched_image)\n",
    "plt.title('Detected Sticker')  # Set title for the display window\n",
    "plt.show()  # Display the image with matched keypoints\n",
    "\n",
    "# Determine whether the object in the test image is similar to the template object based on the number of good matches\n",
    "match_threshold = 11  # Set a threshold for the number of good matches to consider the objects similar\n",
    "\n",
    "if good_matches_count > match_threshold:\n",
    "    print(\"The object in the input image is similar to the object in the template.\")\n",
    "else:\n",
    "    print(\"The object in the input image is NOT similar to the object in the template.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Amanda3venv",
   "language": "python",
   "name": "amanda3venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
